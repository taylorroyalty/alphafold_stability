---
title: "R Notebook"
output: html_notebook
---

This is an [R Markdown](http://rmarkdown.rstudio.com) Notebook. When you execute code within the notebook, the results appear beneath the code. 

Try executing this chunk by clicking the *Run* button within the chunk or by placing your cursor inside it and pressing *Ctrl+Shift+Enter*. 


```{r}
conda.env.bin.path <- "/home/troyalty/Software/bioinformatics/miniconda3/envs/assembly_annotation/bin"
accession.list <- c("SRR7066493")

override <- TRUE

fastq.dump.cores=2

megahit.cores=30
min.contig.length <- 1000

dbcan.db <- 'data/database/dbCAN-HMMdb-V10.txt'
```

```{r}
knitr::opts_chunk$set(engine.opts = list(bash = "-l"))

library(tidyverse)
library(foreach)
library(doParallel)

source("scripts/R/assembly_annotation_functions.R")

```



This pipeline is designed to isolate putative genes from shotgun metagenomic sequence datasets, annotate target genes using dbCAN, and isolate putatively exported proteins. Most functions implement shell commands via subprocesses and require all softwares to be included in the system PATH. In my case, I created a conda environment which includes all the softwares below (with the exception of signalp), and appended that conda environment's bin to my PATH.

The workflow is:
1) append conda environment bin path to PATH
2) create standardized directory structure
3) download short-read datasets from SRA using fastq-dump
4) quality filter short-reads using fastp
5) assemble high-quality reads into contigs using megahit
6) predict putative genes using prodigal
7) create a hmm database using dbCAN definitions
8) annotate genes with dbCAN definitions using HMMER
9) isolate dbCAN-positive genes
10) separate putative extracellular and intracellular enzymes based on signalp predictions--cleave signal peptides

```{r}


#Append conda environment bin path to PATH
Sys.setenv(PATH = paste(Sys.getenv("PATH"), conda.env.bin.path, sep = ":")) 

#create standardized directory
create_sequence_directories(override = override)

#download specified short read datasets
download_SRR(accession.list = accession.list, numCores = fastq.dump.cores)

#trim adaptars and drop low quality reads
trim_reads(accession.list = accession.list)

#assemble short reads into contigs
assemble_reads(accession.list, megahit.cores=megahit.cores, min.contig.length = min.contig.length)

#predict contig ORFs
predict_ORFs(accession.list)

#make a dbcan database
make_database(dbcan.db)

#annotate genes with dbcan annotations
dbcan_annotation(accession.list=accession.list, db=dbcan.db)

#filter and isolate genes annotated with dbcan annotations  
filter_fasta_with_gene_list(accession.list = accession.list, dir.gene.list = "data/sequence/annotation/hmm/", ex_gene_list = "_dbCAN-HMMdb-V10.txt_parsed.tsv", col = 3)

#separate dbCAN-positive annotations in signal peptide-positive and negative sequences--cleave signal peptide
filter_signal_peptide(accession.list = accession.list, faa_ex="_filtered.faa", cleave = TRUE)

```


```{bash echo=TRUE}
#filepath containing fasta files
faa_filepath=/home/troyalty/Documents/projects/alphafold_stability/data/sequence/genes/aa/signalp/extracellular/
#filepath housing alphafold2 run_docker.py script
alphafold2_script=/home/troyalty/Software/alphafold2_docker/alphafold/docker/run_docker.py
#directory to output structure results
output_path=/home/troyalty/Documents/projects/alphafold_stability/data/sequence/structures/
#a temporary directory for writing temporary fasta files
tmp_path=/home/troyalty/Documents/projects/alphafold_stability/tmp/
#directory containing alphafold2 reference data
reference_data=/srv/data/alphafold/

#this allows for using conda's activate command. Note, that conda's path is added to the PATH in ~/.profile. There is apparently some variability in how
#rstudio executes .bashrc, .bash_profile, .profile, etc. among different OS. GL
source activate
conda activate alphafold_docker

rm -fr $tmp_path 2> /dev/null
mkdir $tmp_path

rm -fr $output_path 2> /dev/null
mkdir $output_path


#loop through list 
for f in $faa_filepath; do
  cat $f | while read -r header; do #the while loop iterates through headers and sequences--note this requires the fasta file to be single-line fasta format
		read -r seq #this reads the sequence under the header
		gene_name=$(echo $header | cut -f 1 -d ' ' | cut -f 2 -d '>')
		seq_file=$tmp_path/$gene_name$fa_ex
		
		#alphafold only takes one sequence at at time; this requires isolating sequences in multifasta files into temporary files
		echo $header > $seq_file
		echo $seq >> $seq_file
		
		#run the alphafold2 run_docker.py script
    python3 $alphafold2_script \
      --fasta_paths=data/sequence/genes/aa/signalp/extracellular/tmp.fasta \
      --max_template_date=2020-05-14 \
      --data_dir=$reference_data \
      --output_dir=$output_path
  done
done

rm -fr $tmp_path 2> /dev/null
```


Add a new chunk by clicking the *Insert Chunk* button on the toolbar or by pressing *Ctrl+Alt+I*.

When you save the notebook, an HTML file containing the code and output will be saved alongside it (click the *Preview* button or press *Ctrl+Shift+K* to preview the HTML file).

The preview shows you a rendered HTML copy of the contents of the editor. Consequently, unlike *Knit*, *Preview* does not run any R code chunks. Instead, the output of the chunk when it was last run in the editor is displayed.
